{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook I'm handling the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook I'm trying to see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = loadlocal_mnist(\n",
    "    images_path='fashion/train-images-idx3-ubyte', \n",
    "    labels_path='fashion/train-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = loadlocal_mnist(\n",
    "    images_path='fashion/t10k-images-idx3-ubyte', \n",
    "    labels_path='fashion/t10k-labels-idx1-ubyte')\n",
    "X_test = X_test.reshape((10000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I prepare the train test for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I build some models to compare how they run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model1.add(MaxPool2D(pool_size=(1,1)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.4373 - accuracy: 0.8470 - val_loss: 0.3355 - val_accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.2896 - accuracy: 0.8958 - val_loss: 0.3136 - val_accuracy: 0.8843\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.2421 - accuracy: 0.9133 - val_loss: 0.2883 - val_accuracy: 0.8982\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.2090 - accuracy: 0.9240 - val_loss: 0.2932 - val_accuracy: 0.8920\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1823 - accuracy: 0.9333 - val_loss: 0.2705 - val_accuracy: 0.9070\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1578 - accuracy: 0.9426 - val_loss: 0.2802 - val_accuracy: 0.9008\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1380 - accuracy: 0.9499 - val_loss: 0.2743 - val_accuracy: 0.9061\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1185 - accuracy: 0.9566 - val_loss: 0.2928 - val_accuracy: 0.9054\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1034 - accuracy: 0.9628 - val_loss: 0.3048 - val_accuracy: 0.9064\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0883 - accuracy: 0.9687 - val_loss: 0.3248 - val_accuracy: 0.9065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4db58c910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model2.add(MaxPool2D(pool_size=(1,1)))\n",
    "model2.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model2.add(MaxPool2D(pool_size=(1,1)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.4393 - accuracy: 0.8444 - val_loss: 0.3399 - val_accuracy: 0.8776\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.2870 - accuracy: 0.8949 - val_loss: 0.3081 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 36s 76ms/step - loss: 0.2374 - accuracy: 0.9147 - val_loss: 0.2733 - val_accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.1962 - accuracy: 0.9280 - val_loss: 0.2680 - val_accuracy: 0.9044\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 38s 81ms/step - loss: 0.1643 - accuracy: 0.9396 - val_loss: 0.2553 - val_accuracy: 0.9127\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 37s 80ms/step - loss: 0.1348 - accuracy: 0.9503 - val_loss: 0.2553 - val_accuracy: 0.9156\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 36s 78ms/step - loss: 0.1051 - accuracy: 0.9620 - val_loss: 0.2631 - val_accuracy: 0.9142\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 37s 78ms/step - loss: 0.0826 - accuracy: 0.9701 - val_loss: 0.2865 - val_accuracy: 0.9165\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 38s 82ms/step - loss: 0.0641 - accuracy: 0.9770 - val_loss: 0.3130 - val_accuracy: 0.9157\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 38s 82ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.3409 - val_accuracy: 0.9110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc13b1ceeb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model3.add(MaxPool2D(pool_size=(1,1)))\n",
    "model3.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='softmax', input_shape=(28,28,1)))\n",
    "model3.add(MaxPool2D(pool_size=(1,1)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 65s 137ms/step - loss: 0.7055 - accuracy: 0.7480 - val_loss: 0.4376 - val_accuracy: 0.8433\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 0.3728 - accuracy: 0.8668 - val_loss: 0.3898 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.3237 - accuracy: 0.8835 - val_loss: 0.3433 - val_accuracy: 0.8754\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.2972 - accuracy: 0.8924 - val_loss: 0.3240 - val_accuracy: 0.8835\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.2728 - accuracy: 0.9010 - val_loss: 0.3020 - val_accuracy: 0.8922\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.2516 - accuracy: 0.9068 - val_loss: 0.2927 - val_accuracy: 0.8977\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.2327 - accuracy: 0.9144 - val_loss: 0.2868 - val_accuracy: 0.8969\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.2182 - accuracy: 0.9187 - val_loss: 0.2831 - val_accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.2049 - accuracy: 0.9246 - val_loss: 0.2898 - val_accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.1907 - accuracy: 0.9301 - val_loss: 0.2891 - val_accuracy: 0.8987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4de104790>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='softmax', input_shape=(28,28,1)))\n",
    "model4.add(MaxPool2D(pool_size=(1,1)))\n",
    "model4.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='softmax', input_shape=(28,28,1)))\n",
    "model4.add(MaxPool2D(pool_size=(1,1)))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 66s 138ms/step - loss: 2.3049 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 2.3027 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 65s 140ms/step - loss: 2.3027 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4de81c4f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='softmax', input_shape=(28,28,1)))\n",
    "model5.add(MaxPool2D(pool_size=(1,1)))\n",
    "model5.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model5.add(MaxPool2D(pool_size=(1,1)))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(100, activation='relu'))\n",
    "model5.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.7125 - accuracy: 0.7419 - val_loss: 0.5206 - val_accuracy: 0.8117\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 0.4560 - accuracy: 0.8340 - val_loss: 0.4558 - val_accuracy: 0.8346\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.3937 - accuracy: 0.8582 - val_loss: 0.4002 - val_accuracy: 0.8564\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.3512 - accuracy: 0.8728 - val_loss: 0.3606 - val_accuracy: 0.8698\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 59s 126ms/step - loss: 0.3172 - accuracy: 0.8852 - val_loss: 0.3340 - val_accuracy: 0.8812\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 0.2936 - accuracy: 0.8928 - val_loss: 0.3258 - val_accuracy: 0.8809\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.2736 - accuracy: 0.8999 - val_loss: 0.3092 - val_accuracy: 0.8856\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.2583 - accuracy: 0.9045 - val_loss: 0.3063 - val_accuracy: 0.8871\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.2469 - accuracy: 0.9081 - val_loss: 0.3035 - val_accuracy: 0.8910\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.2340 - accuracy: 0.9134 - val_loss: 0.3121 - val_accuracy: 0.8874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4e5bcc5e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model6.add(MaxPool2D(pool_size=(1,1)))\n",
    "model6.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model6.add(MaxPool2D(pool_size=(1,1)))\n",
    "model6.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model6.add(MaxPool2D(pool_size=(1,1)))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(100, activation='relu'))\n",
    "model6.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 93s 197ms/step - loss: 0.4499 - accuracy: 0.8387 - val_loss: 0.3279 - val_accuracy: 0.8856\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 81s 173ms/step - loss: 0.2820 - accuracy: 0.8972 - val_loss: 0.2850 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 94s 200ms/step - loss: 0.2283 - accuracy: 0.9166 - val_loss: 0.2586 - val_accuracy: 0.9066\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 82s 174ms/step - loss: 0.1878 - accuracy: 0.9311 - val_loss: 0.2539 - val_accuracy: 0.9103\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 83s 176ms/step - loss: 0.1544 - accuracy: 0.9431 - val_loss: 0.2437 - val_accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 91s 195ms/step - loss: 0.1201 - accuracy: 0.9566 - val_loss: 0.2551 - val_accuracy: 0.9142\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 84s 179ms/step - loss: 0.0922 - accuracy: 0.9659 - val_loss: 0.2672 - val_accuracy: 0.9161\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 0.0691 - accuracy: 0.9741 - val_loss: 0.3015 - val_accuracy: 0.9121\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 95s 203ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 0.3666 - val_accuracy: 0.9130\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 85s 182ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.3664 - val_accuracy: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4c1cbfa30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model7.add(MaxPool2D(pool_size=(1,1)))\n",
    "model7.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model7.add(MaxPool2D(pool_size=(1,1)))\n",
    "model7.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model7.add(MaxPool2D(pool_size=(1,1)))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(100, activation='relu'))\n",
    "model7.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 107s 113ms/step - loss: 0.4095 - accuracy: 0.8535 - val_loss: 0.3136 - val_accuracy: 0.8880\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 120s 128ms/step - loss: 0.2600 - accuracy: 0.9048 - val_loss: 0.2869 - val_accuracy: 0.8986\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 123s 132ms/step - loss: 0.2064 - accuracy: 0.9245 - val_loss: 0.2515 - val_accuracy: 0.9097\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.1636 - accuracy: 0.9392 - val_loss: 0.2610 - val_accuracy: 0.9132\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.1247 - accuracy: 0.9537 - val_loss: 0.2754 - val_accuracy: 0.9118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4b28c2e20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(X_train, Y_train, batch_size=64, epochs=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model8.add(MaxPool2D(pool_size=(1,1)))\n",
    "model8.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model8.add(MaxPool2D(pool_size=(1,1)))\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(100, activation='relu'))\n",
    "model8.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.3993 - accuracy: 0.8576 - val_loss: 0.3175 - val_accuracy: 0.8856\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.2597 - accuracy: 0.9053 - val_loss: 0.2922 - val_accuracy: 0.8945\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 75s 80ms/step - loss: 0.2086 - accuracy: 0.9230 - val_loss: 0.2410 - val_accuracy: 0.9113\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 79s 84ms/step - loss: 0.1679 - accuracy: 0.9387 - val_loss: 0.2437 - val_accuracy: 0.9136\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.1335 - accuracy: 0.9514 - val_loss: 0.2639 - val_accuracy: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4b2480e50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.fit(X_train, Y_train, batch_size=64, epochs=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I compare and contrast those models, model2 gives me the best value for my money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"cnn_fashion_model2.ckpt\",\n",
    "                                              save_weights_only=True,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "final_model.add(MaxPool2D(pool_size=(1,1)))\n",
    "final_model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "final_model.add(MaxPool2D(pool_size=(1,1)))\n",
    "final_model.add(Flatten())\n",
    "final_model.add(Dense(100, activation='relu'))\n",
    "final_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4393 - accuracy: 0.8444\n",
      "Epoch 1: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 39s 83ms/step - loss: 0.4393 - accuracy: 0.8444 - val_loss: 0.3399 - val_accuracy: 0.8776\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.8949\n",
      "Epoch 2: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.2870 - accuracy: 0.8949 - val_loss: 0.3081 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.9147\n",
      "Epoch 3: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.2374 - accuracy: 0.9147 - val_loss: 0.2733 - val_accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9280\n",
      "Epoch 4: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.1962 - accuracy: 0.9280 - val_loss: 0.2680 - val_accuracy: 0.9044\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9396\n",
      "Epoch 5: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 51s 108ms/step - loss: 0.1643 - accuracy: 0.9396 - val_loss: 0.2553 - val_accuracy: 0.9127\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9503\n",
      "Epoch 6: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 0.1348 - accuracy: 0.9503 - val_loss: 0.2553 - val_accuracy: 0.9156\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9620\n",
      "Epoch 7: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 59s 125ms/step - loss: 0.1051 - accuracy: 0.9620 - val_loss: 0.2631 - val_accuracy: 0.9142\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9701\n",
      "Epoch 8: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 53s 112ms/step - loss: 0.0826 - accuracy: 0.9701 - val_loss: 0.2865 - val_accuracy: 0.9165\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9770\n",
      "Epoch 9: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0641 - accuracy: 0.9770 - val_loss: 0.3130 - val_accuracy: 0.9157\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9818\n",
      "Epoch 10: saving model to cnn_fashion_model2.ckpt\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.3409 - val_accuracy: 0.9110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f73e7eee0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(final_model.predict(X_train[0].reshape((1,28,28,1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(final_model.predict(X_train[1].reshape((1,28,28,1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(final_model.predict(X_train[2].reshape((1,28,28,1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Sequential()\n",
    "loaded_model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "loaded_model.add(MaxPool2D(pool_size=(1,1)))\n",
    "loaded_model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "loaded_model.add(MaxPool2D(pool_size=(1,1)))\n",
    "loaded_model.add(Flatten())\n",
    "loaded_model.add(Dense(100, activation='relu'))\n",
    "loaded_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9f755ab790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.load_weights(\"cnn_fashion_model2.ckpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(loaded_model.predict(X_train[0].reshape((1,28,28,1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(loaded_model.predict(X_train[1].reshape((1,28,28,1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(loaded_model.predict(X_train[2].reshape((1,28,28,1))), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}